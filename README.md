# jargonaut
WIP - We use Llama-3.1 to generate synthetic Q&amp;A pairs for jargon-heavy text data. Then, we use the synthetic data to finetune an embeddings model. By finetuning an embeddings model, we hope to improve the accessibility of the data to people without specialist knowledge of the subject matter. 
